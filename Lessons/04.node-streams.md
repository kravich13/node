# Streams

- [Streams](#streams)
	- [Intro](#intro)
	- [Types of Streams](#types-of-streams)
	- [Events](#events)
		- [`readable.on(`**`'data'`**`, callback)`](#readableondata-callback)
		- [`readable.on('`**`readable'`**`)`](#readableonreadable)
		- [`readable.on(`**`'pause'`**`)`](#readableonpause)
		- [`readable.on(`**`'resume'`**`)`](#readableonresume)
		- [`writable.on(`**`'close'`**`)`](#writableonclose)
		- [`writable.on(`**`'drain'`**`)`](#writableondrain)
		- [`writable.on(`**`'finish'`**`)`](#writableonfinish)
		- [`writable.on(`**`'pipe'`**`)`](#writableonpipe)
		- [`writable.on(`**`'unpipe'`**`)`](#writableonunpipe)
	- [Methods](#methods)
	- [Create](#create)
		- [Readable](#readable)
		- [Writable](#writable)

***

## Intro

Stream is a concept that allows **processing data by little pieces** or **chunks**.

Example: send file to the client **at once** and using **streams and chunks**

```js
// 1 - simply send a file
async function sendFile(req, req, next) {
	fs.readFile('01. Dreaming Wide Awake.mp3', (err, data) => {
		if (err) {
			throw err
		}
		res.end(data)
	})
}

// 2 - send a file using streams and chunks
async function sendFile(req, req, next) {
	const fileStream = fs.createReadStream('path to file')
	res.contentType('application/pdf')
	fileStream.pipe(res)
}
```

***


## Types of Streams

There are 4 types of streams in node:

1. `Readable` - read (**req**)
2. `Writable` - write (**res**)
3. `Duplex` - both
4. `Transform` - a variation of duplex allowing to change data


***


## Events

Event|Description
-|-
`stream.on('data', callback)`|Emitter whenever the stream is relinquishing ownership of a chunk of data to a consumer. Usually after calling `readable.pipe()`, `readable.resume()`, `readable.read()` or attaching the `data` handler. 
`readable.on('readable' ...)`|When there is data available to be read from the stream (`stream.read()` will return **data**). Will also be emitted in the end, just before the `end` event (`stream.read()` will return `null`).
`readable`|
`close`|Stream has been closed, no more events will be emitted, and no further computation will occur.
`end`|Emitted when there is no more data to be **read** from the stream.
`finish`|Emitted after the `stream.end()` method has been called, and all data has been flushed to the underlying system.
`pause`|When `stream.pause()` is called and `readableFlowing` is not `false`.


### `readable.on(`**`'data'`**`, callback)`

Emitter every time a new chunk of data is relinquished to a comsumer. This may occur whenever the stream is **switched in flowing mode** by:

- `readable.pipe()`
- `readable.resume()`
- `readable.read()` (and the data is available)
- attaching the `data` handler

**NB**: Attaching a `'data'` event listener to a stream that has not been explicitly paused will **switch the stream into flowing mode**. Data will then be passed as soon as it is available.

If `readable.setEncoding()` was used to set the default encoding, then the chunk of data will be passes as a `string`, otherwise - as a `Buffer`.

```js
const readable = getReadableStreamSomehow()
readable.on('data', (chunk) => {
	console.log(`Received ${chunk.length} bytes of data.`)
})
readable.on('end', () => {
	console.log('There will be no more data.')
})

/* ...
Received 65536 bytes of data.
Received 36595 bytes of data.
There will be no more data. */

```

**NB**: The default chunk size is **2 kB**.

***


### `readable.on('`**`readable'`**`)`

Needs to be used with `stream.read()`.

Emitted when there is data available to be read from the stream (`stream.read()` will return **data** in this case). Will also be emitted at the end, just before the `end` event (`stream.read()` will return `null`).

```js
const readable = getReadableStreamSomehow()
readable.on('readable', function () {
	// There is some data to read now.
	let data

	while (data = this.read()) {
		console.log(data)
	}
})
```

For an empty file:

```js
const fs = require('fs')
const rr = fs.createReadStream('foo.txt')
rr.on('readable', () => {
	console.log(`readable: ${rr.read()}`)
})
rr.on('end', () => {
	console.log('end')
})

// readable: null
// end
```

If both `'readable'` and `'data'` are used at the same time, `'readable'` takes precedence in controlling the flow, i.e. `'data'` will be emitted only when `stream.read()` is called. The `readableFlowing` property would become `false`. If there are `'data'` listeners when `'readable'` is removed, the stream will start flowing, i.e. `'data'` events will be emitted without calling `.resume()`.

***


### `readable.on(`**`'pause'`**`)`

Emitted when `stream.pause()` is called and `readableFlowing` is not `false`.

***


### `readable.on(`**`'resume'`**`)`

Emitted when `stream.resume()` is called and `readableFlowing` is not `true`.

***



### `writable.on(`**`'close'`**`)`

Emitted when the stream and any of its underlying resources (e.g. a file descriptor) have been closed. The event indicates that **no more events will be emitted**, and **no further computation will occur**.

A `Writable` stream will always emit the `'close'` event if it is created with the `emitClose` option.

***


### `writable.on(`**`'drain'`**`)`

If a call to `stream.write(chunk)` returns `false`, the `'drain'` event will be emitted when it is appropriate to resume writing data to the stream.



TO ADD EXAMPLE


***


### `writable.on(`**`'finish'`**`)`

Emitted after the `stream.end()` method has been called, and all data has been flushed to the underlying system.



TO ADD EXAMPLE


***


### `writable.on(`**`'pipe'`**`)`

Emitted when the `stream.pipe()` method is called on a `Readable` stream, adding this `writable` to its set of destinations.


TO ADD EXAMPLE



***


### `writable.on(`**`'unpipe'`**`)`

Emitted when the `stream.unpipe()` method is called on a `Readable` stream, removing this `Writable` from its set of destinations.

Also emitted in case this `Writable` stream emits an **error** when a `Readable` stream pipes into it.


TO ADD EXAMPLE



***



## Methods

Metod|Description
`stream.destroy()`|

***



## Create

There are 2 ways to create stream:

```js
const { Readable } = require('stream')

// 1 - constructor
const myReadable = new Readable(opt)

// 2 - class extension
class myReadable extends Readable {
	constructor(opt){
		super(opt)
	}

	_read(size){}
}
```

We'll use the 2nd way. Either way, it takes a set of options. Some of them:

- `hightWaterMark` - max **buffer** size in bytes. Reading continues after the buffer is **empty** again (after `pipe`, `resume` or after processing the `data` event)
- `_read()` - protected method called implicitly until `highWaterMark` is reached. 
- `push()` - adds data to the **buffer**. Returns `false` if the buffer is full, `true` - otherwise. 

***


### Readable

Example: 

```js
const { Readable } = require('stream')

class Counter extends Readable {
	constructor(opt){
		super(opt)

		this._max = 100
		this._index = 0
	}

	_read(){
		this._index += 1
		if(this._index > this._max){
			this.push(null)
		} else {
			const buf = Buffer.from(`${this._index}`, 'utf8')
			console.log(`Added ${this._index}. Could be added? ${this.push(buf)}`)
		}
	}
}

const counter = new Counter({ highWaterMark: 2 })
console.log(`Received ${counter.read()}`)	// change this later
```

![](img/2020-09-23-16-39-34.png)

What happened here? 

1. In `new Counter({ highWaterMark: 2 })` we set the size of our inner buffer to **2 bytes**. Thus, it can store **2** of 1-byte (`utf8`) characters. 
2. `counter.read()` starts reading. 
   1. It writes '1' to the buffer.
   2. `Readable.push` - `return true` - can continue
   3. Repeat **1-2** for '2' 
   4. When the stream tries to write '3', `Readable.push()` will `return false` and the stream will wait until the **buffer** is empty. We don't have the buffer emptying yet, so the reading stops here. 

Let's add buffer emptying. Change the last line to this:

```js
counter.on('data', chunk => {
	console.log(`Received: ${chunk}`)
})
```

Now it counts from 1 to 100.

***


### Writable 

```js
const { Writable } = require('stream')

class myWritable extends Writable {
  	constructor(opt) {
    	super(opt)
  	}

  	_write(chunk, encoding, callback) {}
}
```

Similar to Readable:

- `_write(chunk, encoding, callback)` - called implicitly for writing a portion of data. Encoding is used is the data is `string`. 
- `highWaterMark` - max buffer size in bytes (16KB by default).